# Proyecto de DetecciÃ³n de Fraude con Redes Neuronales

Este proyecto implementa un modelo de red neuronal para la detecciÃ³n de fraudes en transacciones de tarjeta de crÃ©dito, utilizando el famoso dataset de Kaggle [`creditcard.csv`](https://www.kaggle.com/mlg-ulb/creditcardfraud). Se incluyen herramientas de visualizaciÃ³n, mÃ©tricas y anÃ¡lisis de performance comparado con regresiÃ³n logÃ­stica.

---

## ğŸ“ Estructura del Proyecto

```
fraud_detection/
â”‚
â”œâ”€â”€ data/                    # Datos originales y procesados
â”‚
â”œâ”€â”€ notebooks/               # Notebooks principales
â”‚   â”œâ”€â”€ EDA.ipynb            # AnÃ¡lisis exploratorio de datos
â”‚   â”œâ”€â”€ RedNeuronal.ipynb    # Entrenamiento y visualizaciÃ³n DNN
â”‚   â”œâ”€â”€ Evaluacion.ipynb     # ComparaciÃ³n con regresiÃ³n logÃ­stica
â”‚   â””â”€â”€ runColab.ipynb       # VersiÃ³n compacta para Google Colab
â”‚
â”œâ”€â”€ src/                     # MÃ³dulos reutilizables
â”‚   â”œâ”€â”€ preprocess.py        # Procesamiento de datos, reducciÃ³n y balanceo
â”‚   â”œâ”€â”€ train.py             # Entrenamiento de modelos
â”‚   â”œâ”€â”€ evaluate.py          # MÃ©tricas y visualizaciÃ³n de performance
â”‚   â”œâ”€â”€ model.py             # Arquitecturas disponibles
â”‚   â””â”€â”€ utils.py             # Funciones auxiliares (plots, configuraciones)
â”‚
â”œâ”€â”€ models/                  # Modelos entrenados en formato .keras
â”‚
â”œâ”€â”€ config.yaml              # ParÃ¡metros del modelo, entrenamiento y paths
â”œâ”€â”€ requirements.txt         # LibrerÃ­as necesarias
â””â”€â”€ README.md                # Este archivo
```

---

## âš™ï¸ EjecuciÃ³n del proyecto

### ğŸ”§ 1. Crear y activar entorno virtual (recomendado)

```bash
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### ğŸ§ª 2. Procesar datos

```bash
python src/preprocess.py
```

Esto genera los archivos procesados balanceados o completos, segÃºn la configuraciÃ³n en `config.yaml`.

---

## ğŸ“¦ Archivos generados por `preprocess.py`

El script `src/preprocess.py` genera diferentes conjuntos de datos dependiendo de la configuraciÃ³n en `config.yaml`.

### ğŸ› ï¸ ConfiguraciÃ³n relevante en `config.yaml`

```yaml
preprocessing:
  sample_size: 10000       # TamaÃ±o total del dataset (puede ser None para usar todo)
  subsample: true          # True = crear dataset balanceado para entrenamiento
```

### ğŸ“ Archivos generados en `data/processed/`

| Archivo               | DescripciÃ³n |
|-----------------------|-------------|
| `train_full.csv`      | Dataset de entrenamiento completo, con clases desbalanceadas (para usar con `class_weight`) |
| `train.csv`           | Dataset balanceado por submuestreo (fraude = no fraude), generado si `subsample=True` |
| `val.csv`             | Conjunto de validaciÃ³n, comÃºn para ambos casos |
| `test.csv`            | Conjunto de test sobre los datos originales, desbalanceado |
| `test_balanced.csv`   | Conjunto de test balanceado, generado solo si `subsample=True` |

âœ… Esto permite entrenar con dos flujos:
- Dataset balanceado (`train.csv`) sin `class_weight`
- Dataset completo (`train_full.csv`) usando `class_weight=True`

Y evaluar en:
- Test realista (`test.csv`)
- Test balanceado (`test_balanced.csv`)

---

## ğŸ§  ParÃ¡metros de configuraciÃ³n (`config.yaml`)

```yaml
model:
  model_type: deep          # Opciones: simple, deep
  units1: 32
  units2: 16
  dropout: 0.3
  l2: 0.001                 # RegularizaciÃ³n L2
  optimizer: adam

training:
  epochs: 50
  batch_size: 128
  use_class_weight: true    # PonderaciÃ³n por clase
  use_early_stopping: true  # DetenciÃ³n temprana

preprocessing:
  sample_size: 1000000      # NÃºmero total de muestras a usar
  subsample: false          # Usar undersampling balanceado
  random_state: 42

evaluation:
  use_balanced_test: false
```

---

## ğŸ“Š Visualizaciones disponibles

- Matriz de correlaciÃ³n de variables (`plot_correlation_matrix`)
- Score vs Threshold con F1-score (`plot_f1_vs_threshold`)
- Curva ROC comparativa
- KS test para seÃ±al/background (train vs test)
- DistribuciÃ³n de scores por clase (`plot_score_distribution`)
- Matriz de confusiÃ³n con mÃ©tricas

---

## ğŸ“ Notas

- El dataset original estÃ¡ desbalanceado (solo 492 fraudes sobre 284,000 transacciones).
- Puedes ajustar el threshold de decisiÃ³n (`0.5 â†’ 0.95`) para priorizar recall o precisiÃ³n.
- El modelo de red neuronal puede sobreajustarse si no se usa regularizaciÃ³n o `early stopping`.

---

## â–¶ï¸ Ejecutar en Google Colab

Puedes ejecutar todo el proyecto directamente desde Google Colab haciendo clic en el siguiente botÃ³n:

[![Abrir en Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/solivare/DeepNeuralNetworkUSS/blob/main/Examples/Fraud/notebooks/runColab.ipynb)

---
