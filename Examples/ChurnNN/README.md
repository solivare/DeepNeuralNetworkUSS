# ğŸ” Proyecto de Deep Learning â€“ PredicciÃ³n de Abandono de Clientes (Churn)

Este proyecto entrena una red neuronal para predecir si un cliente abandonarÃ¡ un servicio, basado en variables como cantidad de compras, contacto con soporte tÃ©cnico, dÃ­as inactivo, etc.

---

## ğŸ“ Estructura del Proyecto

```
ChurnNN/
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ main.ipynb              # Notebook con entrenamiento y evaluaciÃ³n
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ model.py                   # DefiniciÃ³n del modelo Keras
â”‚   â”œâ”€â”€ utils.py                   # Funciones de visualizaciÃ³n y mÃ©tricas
â”‚   â””â”€â”€ config.yaml                # ConfiguraciÃ³n editable del modelo
â”œâ”€â”€ data/
â”‚   â””â”€â”€ churn_dataset.csv # Dataset simulado
â”œâ”€â”€ setup.sh                       # Script para preparar entorno local
â”œâ”€â”€ requirements.txt               # LibrerÃ­as necesarias
â””â”€â”€ README.md                      # Este archivo
```

---

## Cambios ejecutados al archivo main.ipynb y config.yaml para mejorar el modelo base

### Balanceo de clases:
Debido a las diferencias en los soportes de las clases, se implementÃ³ "class_weight" de la siguiente forma:

weights = class_weight.compute_class_weight(class_weight='balanced',
                                            classes=np.unique(y_train),
                                            y=y_train)

class_weights = dict(zip(np.unique(y_train), weights))

Antes de aplicar balanceo el Accuracy del modelo era de 87% y la precisiÃ³n del 92,6%. Sin embargo la mÃ©trica mÃ¡s relevante del modelo (Recall) era del 89%. Sin embargo, luego de aplicar el balanceo de clases, y luego de varias iteraciones en el archivo config.yaml, no se logrÃ³ mejorar el Recall de la clase 1, el cual es la mas importante del modelo (Un cliente que pude haber retenido.). La mÃ¡xima encontrada fuÃ© 86% con los siguientes parÃ¡metros:

model:
  hidden_units: [64, 32, 16]       
  activation: tanh            
  output_activation: sigmoid  

training:
  batch_size: 32              
  epochs: 100                 
  optimizer: adam             
  loss: binary_crossentropy   


