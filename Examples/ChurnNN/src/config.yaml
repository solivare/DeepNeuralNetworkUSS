# Configuraci贸n del modelo neuronal y entrenamiento
# Estos par谩metros son cargados por main.ipynb y usados por model.py

model:
  hidden_units: [16, 8]       # Neuronas en capas ocultas
  activation: relu            # Funci贸n de activaci贸n de las capas ocultas
  output_activation: sigmoid  # Activaci贸n de la salida (probabilidad de churn)
  dropout_rate: 0.3           #  NUEVO: Tasa de Dropout para regularizaci贸n

training:
  batch_size: 32              # Tama帽o de batch
  epochs: 50                  # N煤mero de 茅pocas de entrenamiento
  optimizer: adam             # Optimizador
  loss: binary_crossentropy   # Funci贸n de p茅rdida (clasificaci贸n binaria)
  early_stopping:             #  NUEVO: Detener si no mejora
    patience: 5
    monitor: val_loss